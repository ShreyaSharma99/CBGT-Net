# -*- coding: utf-8 -*-
"""
.. module:: cbgt_net
    :platform: Linux, Windows, OSX
    :synopsis: Definition of the CGBT-Net architecture.

.. moduleauthor:: AARTLab <danahugh@andrew.cmu.edu>

This file contains a class defining the CBGT-Net architecture.  The CBGT_Net
class is not intended to define a full network architecture; rather, the class
should be used to define an architecture through the composition of evidence,
accumulator, and threshold modules.

Requirements
------------
Tensorflow 2.8
"""

import numpy as np

import tensorflow as tf
import logging

from ..utils import Observable

from .simple_accumulator import SimpleAccumulatorModule
from .evidence_mlp import EvidenceMLPModule
from .fixed_threshold import FixedDecisionThresholdModule


class CBGT_Net(tf.keras.Model,Observable):
    """
    CBGT_Net is a model that is designed to mimic the Cortico-Basal Ganglia-
    Thalamic (CBGT) circuit in the human brain, in order to accumulate evidence
    for decisions.  The CBGT_Net class consists of several modules defining
    the following individual networks:

    * **Evidence Module**: A module that maps observations to evidence vectors.
    * **Accumulation Module**: A module that maintains the cummulative evidence
      received so far.
    * ** Threshold Module**: A module that determines the decision threshold
      level.

    Attributes
    ----------
    num_categories : int
        Number of decision categories available, used to define the size of the
        evidence and accumulation vectors.
    evidence_module : keras.layers.Layer
        Neural network model for calculating evidence vector from observation
    accumulator_module : keras.layers.Layer
        Neural network model for calculating acumulator value from evidence
    threshold_module : keras.layers.Layer
        Neural network model for calculating the decision threshold
    """

    def __init__(self, num_categories,
                 evidence_module=None,
                 accumulator_module=None,
                 threshold_module=None, 
                 **kwargs):
        """
        Arguments
        ---------
        num_categories : int
            Number of decision categories available
        evidence_module : keras.layers.Layer, default=None
            Evidence module to use.  If not provided, an MLP module will be
            created.
        accumulator_module : keras.layers.Layer, default=None
            Accumulator module to use.  If not provided, as SimpleAccumulator
            module will be created.
        threshold_module : keras.layers.Layer, default=None
            Decision threshold module to use.  If not provided, a fixed 
            threshold module will be created.
        evidence_tensor : tf.Tensor
            Most recent tensor output from the evidence module, or None if
            the module has not been called since reset.

        Keyword Arguments
        -----------------
        decision_threshold : int, default=3
            Decision threshold used for a fixed threshold module, if no threshold
            module is provided.
        log_level : int, default=logging.INFO
            Level of logging generated by this network
        """


        tf.keras.Model.__init__(self)

        # Set up the logger
        self._logger = logging.getLogger(self.__class__.__name__)
        self._logger.setLevel(kwargs.get("log_level", logging.INFO))

        # In order to support varying batch sizes, a semi-private variable with
        # the batch size is maintained.  This is set to None on creation and
        # reset, and is propagated to the evidence and accumulator
        self._batch_size = kwargs.get("batch_size", None)

        # Check that the number of categories is valid
        try:
            self._num_categories = int(num_categories)
        except Exception as e:
            self._logger.error("%s: Number of categories cannot be cast as int: %s", self, str(num_categories))
            raise e

        if self._num_categories <= 0:
            self._logger.error("%s: Number of categories must be greater than 0: %d", self, self._num_categories)
            raise ValueError("Non-positive number of categories: %d" % self._num_categories)

        self._num_categories = num_categories

        # Store the evidence module.  If not provided, simply create an MLP as
        # the default evidence module
        if evidence_module is not None:
            self._evidence_module = evidence_module
        else:
            self._logger.info("%s:  Evidence module not provided.  Creating default EvidenceMLPModule" % self)
            self._evidence_module = EvidenceMLPModule(self._num_categories, 
                                                      name="%s/evidence_module" % self,
                                                      batch_size = self._batch_size)

        # Store the accumulator module.  If not provided, create a simple
        # accumulator module as the default
        if accumulator_module is not None:
            self._accumulator_module = accumulator_module
        else:
            self._logger.info("%s:  Accumulator module not provided.  Creating default SimpleAccumulatorModule" % self)
            self._accumulator_module = SimpleAccumulatorModule(self._num_categories,
                                                               name="%s/accumulator_module" % self,
                                                               batch_size=self._batch_size)

        # Store the decision threshold module.  If not provided, create a fixed
        # decision threshold module as default, using the `decision_threshold`
        # keyword argument as the decision threshold.  If a threshold value
        # isn't provided, simply used 3 as an arbitrarily picked default
        if threshold_module is not None:
            self._threshold_module = threshold_module
        else:
            self._threshold_module = FixedDecisionThresholdModule(decision_threshold=kwargs.get("decision_threshold", 3),
                                                                  name="%s/threshold_module" % self,
                                                                  batch_size=self._batch_size)

        self._choice_preferences = tf.keras.layers.Softmax()

        # Local storage of the evidence tensor
        self._evidence_tensor = None

        # Initialize the observable mixin
        Observable.__init__(self)


    def __str__(self):
        """
        String representation of the model
        """

        return self.__class__.__name__


    @property
    def evidence_module(self):
        return self._evidence_module

    @property
    def evidence_shape(self):
        return self._evidence_module.output_shape

    @property
    def accumulator_shape(self):
        return self._accumulator_module.output_shape
    
    


    @property
    def accumulator_module(self):
        return self._accumulator_module


    @property
    def threshold_module(self):
        return self._threshold_module


    @property
    def evidence_tensor(self):
        return self._evidence_tensor
    

    @property
    def accumulator(self):
        """
        Provides the current value of the accumulator.
        """

        return self.accumulator_module.accumulator_value


    def reset(self):
        """
        Resets the network modules to initial values.
        """

        self.evidence_module.reset()
        self.accumulator_module.reset()

        self._evidence_tensor = None


    def call(self, observation, evidence=None, parallel=False, accumulator=None, training=None):
        """
        Process the received observation, returning the distribution over
        choices and accumulated evidence.

        Arguments
        ---------
        observation : tf.Tensor
            Observation received by the model
        accumulator : tf.Tensor, default=None
            Accumulated values.  If provided, these will be passed to the
            accumulator module for use in lieu of the internal accumulator
            contents.
        """

        # Get the batch size from the observation, if needed, and propagate to
        # the evidence and accumulator
#        if self._batch_size is None:
#            self._batch_size = observation.get_shape()[0]

        # Calculate the evidence, choice distribution, and accumulator output
        if not parallel:
            # print("Entering here!!")
            evidence = self.evidence_module(tf.convert_to_tensor(observation, dtype=tf.float32), training=training)
        
        accumulated_evidence = self.accumulator_module(evidence, accumulator, training=training)

        self._evidence_tensor = evidence

        # Return the preference over choices, and whether a choice was made
        # return (self._choice_preferences(accumulated_evidence, training=training), 
        #         self._threshold_module(evidence, accumulated_evidence, training=training))
        
        total_sum = tf.reduce_sum(accumulated_evidence, axis=1, keepdims=True)
        # v = (accumulated_evidence/total_sum)[0, :]
        # tf.print("Acc evidence shape = ", v[0], v[1], v[2], v[3], v[4], v[5], v[6], v[7], v[8], v[9], tf.reduce_sum(v))
        # return (accumulated_evidence/tf.math.sum(accumulated_evidence, axis=-1), 
        return (accumulated_evidence/total_sum,
                self._threshold_module(evidence, accumulated_evidence, training=training))
