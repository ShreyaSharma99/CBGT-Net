{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 01:33:24.564662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-16 01:33:25.212953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist    \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = (x_train/255).astype(float)\n",
    "# x_test = (x_test/255).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  24, 209, 254, 254, 254, 171,   0],\n",
       "       [  0,   0,  91, 137, 253, 254, 254, 254, 112,   0],\n",
       "       [ 40, 214, 250, 254, 254, 254, 254, 254,  34,   0],\n",
       "       [ 81, 247, 254, 254, 254, 254, 254, 254, 146,   0],\n",
       "       [  0, 110, 246, 254, 254, 254, 254, 254, 171,   0],\n",
       "       [  0,   0,  73,  89,  89,  93, 240, 254, 171,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 128, 254, 219,  31],\n",
       "       [  0,   0,   0,   0,   0,   7, 254, 254, 214,  28],\n",
       "       [  0,   0,   0,   0,   0, 138, 254, 254, 116,   0],\n",
       "       [  0,   0,   0,   0,  25, 240, 254, 254,  34,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10, 10:20, 10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_per_class = 1e10\n",
    "for i in range(10):\n",
    "    min_per_class = min(min_per_class, len(np.where(y_test == i)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indx_train, data_indx_test = [], []\n",
    "min_per_class_train = 5421\n",
    "min_per_class_test = 892\n",
    "train_sz, test_sz = 5421, 892\n",
    "for i in range(10):\n",
    "    sample_data_train = np.random.choice(np.where(y_train == i)[0], train_sz, replace=False)\n",
    "    sample_data_test = np.random.choice(np.where(y_test == i)[0], test_sz, replace=False)\n",
    "    data_indx_train.append(sample_data_train)\n",
    "    data_indx_test.append(sample_data_test)\n",
    "\n",
    "data_indx_train = np.array(data_indx_train)\n",
    "data_indx_test = np.array(data_indx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[data_indx_test[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.zeros((10, train_sz, 28, 28, 3))\n",
    "data_test = np.zeros((10, test_sz, 28, 28, 3))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(train_sz):\n",
    "        data_train[i, j, :, :, :] = np.repeat(x_train[data_indx_train[i, j],:, :, np.newaxis], repeats=3, axis=2)\n",
    "    for j in range(test_sz):\n",
    "        data_test[i, j, :, :, :] = np.repeat(x_test[data_indx_test[i, j],:, :, np.newaxis], repeats=3, axis=2)\n",
    "\n",
    "# data_train = data_train.astype(np.int8)\n",
    "# data_test = data_test.astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[175.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [ 60.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 220.],\n",
       "       [  4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  63., 239.],\n",
       "       [186.,   3.,   0.,   0.,   0.,   0.,   0.,   0., 241., 253.],\n",
       "       [253.,  62.,   0.,   0.,   0.,   0.,   3., 170., 253., 253.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0, 10, 10:20, 10:20, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 01:33:39.127758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46492 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_data_train = tf.constant(data_train, tf.uint8)\n",
    "image_data_test = tf.constant(data_test, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,  31, 253, 253, 253, 253, 253, 253, 253],\n",
       "       [  0,   0,   2,  95, 122,  14,  14,  14, 123, 253],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   5, 138],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  7,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [177,   7,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_train[0, 10, 10:20, 10:20, 2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.any(data_test<0)\n",
    "tf.reduce_any(image_data_test<0).numpy()\n",
    "# image_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tensor to a file using tf.io\n",
    "tf.io.write_file('minst_full_train.txt', tf.io.serialize_tensor(image_data_train))\n",
    "tf.io.write_file('minst_full_test.txt', tf.io.serialize_tensor(image_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "serialized_tensor_test = tf.io.read_file('minst_full_test.txt')\n",
    "image_data_test = tf.io.parse_tensor(serialized_tensor_test, out_type=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,  31, 253, 253, 253, 253, 253, 253, 253],\n",
       "       [  0,   0,   2,  95, 122,  14,  14,  14, 123, 253],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   5, 138],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  7,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [177,   7,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_train[0, 10, 10:20, 10:20, 2].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj1 = open(\"./mnist_train\" + str(train_sz) + \".pkl\", 'wb')\n",
    "pickle.dump(data_train, fileObj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj2 = open(\"./mnist_test\" + str(test_sz) + \".pkl\", 'wb')\n",
    "pickle.dump(data_test, fileObj2)\n",
    "fileObj2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"./mnist_train\" + str(train_sz) + \".pkl\", 'rb') as f:\n",
    "#     rand = pickle.load(f)\n",
    "# np.all(rand == data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:01:46.901127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4392 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-07-14 11:01:46.901842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6 MB memory:  -> device: 1, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:23:00.0, compute capability: 8.9\n",
      "2023-07-14 11:01:46.902695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 43468 MB memory:  -> device: 2, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2023-07-14 11:01:46.903255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 43902 MB memory:  -> device: 3, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n",
      "2023-07-14 11:01:46.903752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 18334 MB memory:  -> device: 4, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:e1:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with open('mnist_train'+ str(train_sz) +'.pkl', 'rb') as fileObj:\n",
    "    image_data_train = pickle.load(fileObj)\n",
    "\n",
    "with open('mnist_test'+ str(test_sz) +'.pkl', 'rb') as fileObj:\n",
    "    image_data_test = pickle.load(fileObj)\n",
    "\n",
    "# CHANGE : Save pkl data as tensor\n",
    "image_data_train = tf.constant(image_data_train, dtype=tf.float32)\n",
    "image_data_test = tf.constant(image_data_test, tf.float32)\n",
    "\n",
    "\n",
    "# Save the tensor to a file using tf.io\n",
    "tf.io.write_file('mnist_train'+ str(train_sz) +'.txt', tf.io.serialize_tensor(image_data_train))\n",
    "\n",
    "tf.io.write_file('mnist_test'+ str(test_sz) +'.txt', tf.io.serialize_tensor(image_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb174aeaf7a51c41f649d3ef7f44a68097a1c30253f78e9ab0401ce3e06cb8fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
